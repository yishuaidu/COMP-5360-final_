{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## scraping data part 1 ## \n",
    "from bs4 import BeautifulSoup\n",
    "import requests, bs4\n",
    "\n",
    "\n",
    "## this calss only work with webside https://statisticalatlas.com/metro-area/Nevada/Las-Vegas/Overview\n",
    "class Las_Vegas_zip_code():\n",
    "    \"\"\"\n",
    "    This class is only work with webside:\n",
    "    \n",
    "    https://statisticalatlas.com/metro-area/Nevada/Las-Vegas/Overview\n",
    "    \n",
    "    \n",
    "    The main function of this calss is get all zip code of Las Vegas's links. \n",
    "    \n",
    "        \n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,*args,link,**kwargs):\n",
    "        #super(Montgomery_County,self).__init__(*args,**kwargs)\n",
    "        \n",
    "        if link == \"https://statisticalatlas.com/metro-area/Nevada/Las-Vegas/Overview\":\n",
    "            self.__link = link\n",
    "        else:\n",
    "            raise TypeError(\"plz have a right web, https://statisticalatlas.com/metro-area/Nevada/Las-Vegas/Overview\")\n",
    "        \n",
    "    @property\n",
    "    def link(self):\n",
    "        return self.__link\n",
    "    \n",
    "    \n",
    "    \n",
    "    def get_web_soup(self):\n",
    "        \"\"\"\n",
    "        This function get the soup of a link\n",
    "        \n",
    "        return bs4.BeautifulSoup type \n",
    "        \n",
    "        \"\"\"\n",
    "        web = requests.get(self.link)\n",
    "        soup = BeautifulSoup(web.text, \"html.parser\")\n",
    "        return soup\n",
    "    \n",
    "    def get_all_zip_code_link(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        This function get all zip code's link from a link\n",
    "        \n",
    "        return a dic type\n",
    "        \"\"\"\n",
    "        \n",
    "        dic ={}   \n",
    "        zip_code =[]\n",
    "        soup = self.get_web_soup()\n",
    "        for d in soup.find_all(class_=\"info-table-tr row\"):\n",
    "                for i in d.find_all(class_= \"b info-table-title-td col-sm-3\"):\n",
    "                    if (i.get_text() == \"ZIP Codes: \" ):\n",
    "                        for n in d.find_all(\"a\"):\n",
    "                            name = n.get_text()\n",
    "                            zip_code.append(name)\n",
    "                            l = \"http://statisticalatlas.com\" + n.get(\"href\")\n",
    "                            dic[name] = (name,l)\n",
    "        return dic\n",
    "    \n",
    "    \n",
    "    def __str__(self):\n",
    "        \"\"\"\n",
    "        This function shows information \n",
    "        \"\"\"\n",
    "        x =  self.link\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Las_Vegas_Crawler(Las_Vegas_zip_code):\n",
    "    \"\"\"\n",
    "    This derived class that inherits from this parent class which is Las_Vegas class.\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,*args,name,dic,**kwargs):\n",
    "        \n",
    "        super(Las_Vegas_Crawler,self).__init__(*args,**kwargs)\n",
    "        \n",
    "        self.__name = name\n",
    "        self.__dic = dic\n",
    "     \n",
    "    \n",
    "    @property\n",
    "    def name(self):\n",
    "        return self.__name\n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def dic(self):\n",
    "        return self.__dic\n",
    "    \n",
    "    \n",
    "    \n",
    "    def get_zipCode_link(self):\n",
    "        \n",
    "        if (not self.name in self.dic):\n",
    "            print(\"Unknown zip code \" + self.name)\n",
    "        else:\n",
    "            url = self.dic[self.name][1]\n",
    "            \n",
    "            \n",
    "        return url\n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    def getZipCode(self):\n",
    "        \"\"\" \n",
    "        Retrieve a website based on the subject short name and return it as a BeautifulSoup object. \n",
    "        Assumes an existing subjects dictionary.\n",
    "        \"\"\"\n",
    "        if (not self.name in self.dic):\n",
    "            print(\"Unknown zip code \" + self.name)\n",
    "        else:\n",
    "            url = self.dic[self.name][1]\n",
    "            web = requests.get(url)\n",
    "            web.encoding='utf8'\n",
    "            nameSoup = bs4.BeautifulSoup(web.text,\"html.parser\")\n",
    "            return nameSoup\n",
    "        \n",
    "        \n",
    "        \n",
    "         ## Get Household Income ##\n",
    "\n",
    "    def getIncome(self):    \n",
    "        soup = self.getZipCode()\n",
    "        #get webside of Household Income\n",
    "        for row in soup.find_all(class_ = \"nav nav-stacked\"):\n",
    "                b= row.find_all(\"a\")\n",
    "        for i in b:\n",
    "            if ( i.text.strip() == \"Household Income\"):\n",
    "                l= \"http://statisticalatlas.com\" + i.get(\"href\")\n",
    "\n",
    "        # read webside of Household Income  \n",
    "        web = requests.get(l)\n",
    "        web.encoding='utf8'\n",
    "        income = bs4.BeautifulSoup(web.text,\"html.parser\")\n",
    "\n",
    "        qq= income.find(class_ = \"figure-contents\")\n",
    "        qq = qq.find_all(\"title\")\n",
    "\n",
    "        ## we choose the median as household income in this zip code\n",
    "        ## we can see 100% as median of income, so income is above 100%\n",
    "        count =0 \n",
    "        for i in qq:\n",
    "            if (i.text.strip() == \"100.000%\"):\n",
    "                break\n",
    "            count = count +1\n",
    "\n",
    "        # output income\n",
    "            return qq[count-1].text.strip()   \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        ## Get Educational Attainment##\n",
    "\n",
    "    def getEdu(self):    \n",
    "        soup = self.getZipCode()\n",
    "        #get webside of Educational Attainment\n",
    "        for row in soup.find_all(class_ = \"nav nav-stacked\"):\n",
    "                b= row.find_all(\"a\")\n",
    "        for i in b:\n",
    "            if ( i.text.strip() == \"Educational Attainment\"):\n",
    "                l= \"http://statisticalatlas.com\" + i.get(\"href\")\n",
    "\n",
    "        # read webside of Educational Attainment  \n",
    "        web = requests.get(l)\n",
    "        web.encoding='utf8'\n",
    "        income = bs4.BeautifulSoup(web.text,\"html.parser\")\n",
    "\n",
    "        qq= income.find(class_ = \"figure-contents\")\n",
    "        qq = qq.find_all(\"text\")\n",
    "\n",
    "        ## we choose the counts of higher degree as highger educational Attainment in this zip code\n",
    "        ## find the number of counts \n",
    "\n",
    "        return qq[-5].text.strip()\n",
    "    \n",
    "    \n",
    "    \n",
    "    def getEmployment (self):\n",
    "        soup = self.getZipCode()\n",
    "        #get webside of Educational Attainment\n",
    "        for row in soup.find_all(class_ = \"nav nav-stacked\"):\n",
    "                b= row.find_all(\"a\")\n",
    "        for i in b:\n",
    "            if ( i.text.strip() == \"Employment Status\"):\n",
    "                l= \"http://statisticalatlas.com\" + i.get(\"href\")\n",
    "\n",
    "        # read webside of Employment Status  \n",
    "        web = requests.get(l)\n",
    "        web.encoding='utf8'\n",
    "        income = bs4.BeautifulSoup(web.text,\"html.parser\")\n",
    "\n",
    "        qq= income.find(class_ = \"figure-contents\")\n",
    "        qq = qq.find_all(\"text\")\n",
    "\n",
    "        ## we choose the counts of Employment  in this zip code\n",
    "        ## find the number of counts \n",
    "\n",
    "        return qq[-5].text.strip()\n",
    "    \n",
    "    def getRace_W (self):\n",
    "        soup = self.getZipCode()\n",
    "        #get webside of race\n",
    "        for row in soup.find_all(class_ = \"nav nav-stacked\"):\n",
    "                b= row.find_all(\"a\")\n",
    "        for i in b:\n",
    "            if ( i.text.strip() == \"Race and Ethnicity\"):\n",
    "                l= \"http://statisticalatlas.com\" + i.get(\"href\")\n",
    "        # read webside of race  \n",
    "        web = requests.get(l)\n",
    "        web.encoding='utf8'\n",
    "        race = bs4.BeautifulSoup(web.text,\"html.parser\")\n",
    "        qq= race.find(class_ = \"figure-contents\")\n",
    "        qq = qq.find_all(fill=\"#000\")\n",
    "        ## we choose the counts of race of white people  in this zip code\n",
    "        ## find the number of counts \n",
    "\n",
    "        return qq[-11].text.strip()\n",
    "    \n",
    "    def getRace_H (self):\n",
    "        soup = self.getZipCode()\n",
    "        #get webside of race\n",
    "        for row in soup.find_all(class_ = \"nav nav-stacked\"):\n",
    "                b= row.find_all(\"a\")\n",
    "        for i in b:\n",
    "            if ( i.text.strip() == \"Race and Ethnicity\"):\n",
    "                l= \"http://statisticalatlas.com\" + i.get(\"href\")\n",
    "        # read webside of race  \n",
    "        web = requests.get(l)\n",
    "        web.encoding='utf8'\n",
    "        race = bs4.BeautifulSoup(web.text,\"html.parser\")\n",
    "        qq= race.find(class_ = \"figure-contents\")\n",
    "        qq = qq.find_all(fill=\"#000\")\n",
    "\n",
    "        ## we choose the counts of race of white people  in this zip code\n",
    "        ## find the number of counts \n",
    "        return qq[-9].text.strip()\n",
    "\n",
    "    def getRace_B (self):\n",
    "        soup = self.getZipCode()\n",
    "        #get webside of race\n",
    "        for row in soup.find_all(class_ = \"nav nav-stacked\"):\n",
    "                b= row.find_all(\"a\")\n",
    "        for i in b:\n",
    "            if ( i.text.strip() == \"Race and Ethnicity\"):\n",
    "                l= \"http://statisticalatlas.com\" + i.get(\"href\")\n",
    "        # read webside of race  \n",
    "        web = requests.get(l)\n",
    "        web.encoding='utf8'\n",
    "        race = bs4.BeautifulSoup(web.text,\"html.parser\")\n",
    "        qq= race.find(class_ = \"figure-contents\")\n",
    "        qq = qq.find_all(fill=\"#000\")\n",
    "        ## we choose the counts of race of white people  in this zip code\n",
    "        ## find the number of counts \n",
    "        return qq[-7].text.strip()\n",
    "\n",
    "    def getRace_A (self):\n",
    "        soup = self.getZipCode()\n",
    "        #get webside of race\n",
    "        for row in soup.find_all(class_ = \"nav nav-stacked\"):\n",
    "                b= row.find_all(\"a\")\n",
    "        for i in b:\n",
    "            if ( i.text.strip() == \"Race and Ethnicity\"):\n",
    "                l= \"http://statisticalatlas.com\" + i.get(\"href\")\n",
    "        # read webside of race  \n",
    "        web = requests.get(l)\n",
    "        web.encoding='utf8'\n",
    "        race = bs4.BeautifulSoup(web.text,\"html.parser\")\n",
    "        qq= race.find(class_ = \"figure-contents\")\n",
    "        qq = qq.find_all(fill=\"#000\")\n",
    "        ## we choose the counts of race of white people  in this zip code\n",
    "        ## find the number of counts \n",
    "        return qq[-5].text.strip()\n",
    "\n",
    "    def getRace_M (self):\n",
    "        soup = self.getZipCode()\n",
    "        #get webside of race\n",
    "        for row in soup.find_all(class_ = \"nav nav-stacked\"):\n",
    "                b= row.find_all(\"a\")\n",
    "        for i in b:\n",
    "            if ( i.text.strip() == \"Race and Ethnicity\"):\n",
    "                l= \"http://statisticalatlas.com\" + i.get(\"href\")\n",
    "        # read webside of race  \n",
    "        web = requests.get(l)\n",
    "        web.encoding='utf8'\n",
    "        race = bs4.BeautifulSoup(web.text,\"html.parser\")\n",
    "        qq= race.find(class_ = \"figure-contents\")\n",
    "        qq = qq.find_all(fill=\"#000\")\n",
    "        ## we choose the counts of race of white people  in this zip code\n",
    "        ## find the number of counts \n",
    "        return qq[-3].text.strip()\n",
    "\n",
    "    def getRace_o (self):\n",
    "        soup = self.getZipCode()\n",
    "        #get webside of race\n",
    "        for row in soup.find_all(class_ = \"nav nav-stacked\"):\n",
    "                b= row.find_all(\"a\")\n",
    "        for i in b:\n",
    "            if ( i.text.strip() == \"Race and Ethnicity\"):\n",
    "                l= \"http://statisticalatlas.com\" + i.get(\"href\")\n",
    "        # read webside of race  \n",
    "        web = requests.get(l)\n",
    "        web.encoding='utf8'\n",
    "        race = bs4.BeautifulSoup(web.text,\"html.parser\")\n",
    "        qq= race.find(class_ = \"figure-contents\")\n",
    "        qq = qq.find_all(fill=\"#000\")\n",
    "        ## we choose the counts of race of white people  in this zip code\n",
    "        ## find the number of counts \n",
    "        return qq[-1].text.strip()\n",
    "    \n",
    "    def Population(self):\n",
    "        a = self.getZipCode()\n",
    "        for row in a.find_all(alt=\"Population\",title=\"Population\"):\n",
    "            for i in row.find_all(\"td\"):\n",
    "                return i.text.strip()\n",
    "            \n",
    "            \n",
    "    def Households(self):\n",
    "        a = self.getZipCode()\n",
    "        for row in a.find_all(alt=\"Households\",title=\"Households\"):\n",
    "            for i in row.find_all(\"td\"):\n",
    "                return i.text.strip()\n",
    "             \n",
    "        \n",
    "\n",
    "\n",
    "    def __str__(self):\n",
    "        print( self.name)\n",
    "        print(\"link: \"  + self.get_zipCode_link())\n",
    "        print(\"Population: \" + self.Population())\n",
    "        print(\"Households: \" + self.Households())\n",
    "        print(\"Income: \"+ self.getIncome())\n",
    "        print(\"High Eduction: \" + self.getEdu())\n",
    "        print(\"Employment: \" + self.getEmployment())\n",
    "        print(\"White people: \" + self.getRace_W())\n",
    "        print(\"Hispanic people: \" + self.getRace_H())\n",
    "        print(\"Black people: \" + self.getRace_B())\n",
    "        print(\"Asian people: \" + self.getRace_A())\n",
    "        print(\"Mixed people: \" + self.getRace_M())\n",
    "        print(\"Other people: \" + self.getRace_o())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## just only working for specific website\n",
    "\n",
    "link = Las_Vegas_zip_code(link = \"https://statisticalatlas.com/metro-area/Nevada/Las-Vegas/Overview\")\n",
    "soup=link.get_web_soup()\n",
    "ALL_zip_code = link.get_all_zip_code_link()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## example of one zip code \n",
    "#a = Las_Vegas_Crawler(name='89002',dic=ALL_zip_code,link =\"https://statisticalatlas.com/metro-area/Nevada/Las-Vegas/Overview\" )\n",
    "#a.__str__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** Crawler runing *******\n",
      "1/71 ****** 89002\n",
      "2/71 ****** 89004\n",
      "3/71 ****** 89005\n",
      "4/71 ****** 89007\n",
      "5/71 ****** 89011\n",
      "6/71 ****** 89012\n",
      "7/71 ****** 89014\n",
      "8/71 ****** 89015\n",
      "9/71 ****** 89018\n",
      "10/71 ****** 89019\n",
      "11/71 ****** 89021\n",
      "12/71 ****** 89025\n",
      "13/71 ****** 89027\n",
      "14/71 ****** 89029\n",
      "15/71 ****** 89030\n",
      "16/71 ****** 89031\n",
      "17/71 ****** 89032\n",
      "18/71 ****** 89039\n",
      "19/71 ****** 89040\n",
      "20/71 ****** 89044\n",
      "21/71 ****** 89046\n",
      "22/71 ****** 89052\n",
      "23/71 ****** 89054\n",
      "24/71 ****** 89074\n",
      "25/71 ****** 89081\n",
      "26/71 ****** 89084\n",
      "27/71 ****** 89085\n",
      "28/71 ****** 89086\n",
      "29/71 ****** 89101\n",
      "30/71 ****** 89102\n",
      "31/71 ****** 89103\n",
      "32/71 ****** 89104\n",
      "33/71 ****** 89106\n",
      "34/71 ****** 89107\n",
      "35/71 ****** 89108\n",
      "36/71 ****** 89109\n",
      "37/71 ****** 89110\n",
      "38/71 ****** 89113\n",
      "39/71 ****** 89115\n",
      "40/71 ****** 89117\n",
      "41/71 ****** 89118\n",
      "42/71 ****** 89119\n",
      "43/71 ****** 89120\n",
      "44/71 ****** 89121\n",
      "45/71 ****** 89122\n",
      "46/71 ****** 89123\n",
      "47/71 ****** 89124\n",
      "48/71 ****** 89128\n",
      "49/71 ****** 89129\n",
      "50/71 ****** 89130\n",
      "51/71 ****** 89131\n",
      "52/71 ****** 89134\n",
      "53/71 ****** 89135\n",
      "54/71 ****** 89138\n",
      "55/71 ****** 89139\n",
      "56/71 ****** 89141\n",
      "57/71 ****** 89142\n",
      "58/71 ****** 89143\n",
      "59/71 ****** 89144\n",
      "60/71 ****** 89145\n",
      "61/71 ****** 89146\n",
      "62/71 ****** 89147\n",
      "63/71 ****** 89148\n",
      "64/71 ****** 89149\n",
      "65/71 ****** 89156\n",
      "66/71 ****** 89161\n",
      "67/71 ****** 89166\n",
      "68/71 ****** 89169\n",
      "69/71 ****** 89178\n",
      "70/71 ****** 89179\n",
      "71/71 ****** 89183\n",
      "****** Crawler End *******\n"
     ]
    }
   ],
   "source": [
    "zip_=[]\n",
    "Population =[]\n",
    "income =[]\n",
    "edu_high =[]\n",
    "Emp=[]\n",
    "Race_w=[]\n",
    "Race_h=[]\n",
    "Race_b=[]\n",
    "Race_a=[]\n",
    "Race_m=[]\n",
    "Race_o=[]\n",
    "\n",
    "Households=[]\n",
    "\n",
    "\n",
    "count = 0\n",
    "\n",
    "print(\"****** Crawler runing *******\")\n",
    "all_zip_list = list(ALL_zip_code.keys())\n",
    "\n",
    "## useless zip code\n",
    "all_zip_list.remove('89026')\n",
    "all_zip_list.remove('89191')\n",
    "\n",
    "for i in all_zip_list:\n",
    "    a = Las_Vegas_Crawler(name=i,dic=ALL_zip_code,link =\"https://statisticalatlas.com/metro-area/Nevada/Las-Vegas/Overview\" )\n",
    "    print(str(count+1)+\"/\"+str(len(all_zip_list)) + \" ****** \" + str(i))\n",
    "    zip_.append(i)\n",
    "    Population.append(a.Population())\n",
    "    income.append(a.getIncome())\n",
    "    edu_high.append(a.getEdu())\n",
    "    Emp.append(a.getEmployment())\n",
    "    Race_w.append(a.getRace_W())\n",
    "    Race_h.append(a.getRace_H())\n",
    "    Race_b.append(a.getRace_B())\n",
    "    Race_a.append(a.getRace_A())\n",
    "    Race_m.append(a.getRace_M())\n",
    "    Race_o.append(a.getRace_o())\n",
    "\n",
    "    Households.append(a.Households())\n",
    "    count = count +1\n",
    "    \n",
    "print(\"****** Crawler End *******\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zip</th>\n",
       "      <th>Population</th>\n",
       "      <th>income</th>\n",
       "      <th>edu_high</th>\n",
       "      <th>Emp</th>\n",
       "      <th>Race_w</th>\n",
       "      <th>Race_h</th>\n",
       "      <th>Race_b</th>\n",
       "      <th>Race_a</th>\n",
       "      <th>Race_m</th>\n",
       "      <th>Race_o</th>\n",
       "      <th>Households</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>89002</td>\n",
       "      <td>34,343</td>\n",
       "      <td>$196,338.000000</td>\n",
       "      <td>7,825</td>\n",
       "      <td>15.7k</td>\n",
       "      <td>26.1k</td>\n",
       "      <td>4,746</td>\n",
       "      <td>1,027</td>\n",
       "      <td>1,403</td>\n",
       "      <td>955</td>\n",
       "      <td>124</td>\n",
       "      <td>11,431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>89004</td>\n",
       "      <td>345</td>\n",
       "      <td>$250,001.000000</td>\n",
       "      <td>168</td>\n",
       "      <td>177</td>\n",
       "      <td>329</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>89005</td>\n",
       "      <td>15,373</td>\n",
       "      <td>$188,448.000000</td>\n",
       "      <td>4,269</td>\n",
       "      <td>6,041</td>\n",
       "      <td>13.0k</td>\n",
       "      <td>1,408</td>\n",
       "      <td>51</td>\n",
       "      <td>401</td>\n",
       "      <td>386</td>\n",
       "      <td>172</td>\n",
       "      <td>6,256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89007</td>\n",
       "      <td>1,423</td>\n",
       "      <td>$104,827.000000</td>\n",
       "      <td>65</td>\n",
       "      <td>489</td>\n",
       "      <td>772</td>\n",
       "      <td>605</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>89011</td>\n",
       "      <td>21,506</td>\n",
       "      <td>$181,331.000000</td>\n",
       "      <td>4,964</td>\n",
       "      <td>10.6k</td>\n",
       "      <td>12.8k</td>\n",
       "      <td>4,081</td>\n",
       "      <td>2,121</td>\n",
       "      <td>1,624</td>\n",
       "      <td>820</td>\n",
       "      <td>106</td>\n",
       "      <td>8,290</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     zip Population           income edu_high    Emp Race_w Race_h Race_b  \\\n",
       "0  89002     34,343  $196,338.000000    7,825  15.7k  26.1k  4,746  1,027   \n",
       "1  89004        345  $250,001.000000      168    177    329     10      0   \n",
       "2  89005     15,373  $188,448.000000    4,269  6,041  13.0k  1,408     51   \n",
       "3  89007      1,423  $104,827.000000       65    489    772    605      0   \n",
       "4  89011     21,506  $181,331.000000    4,964  10.6k  12.8k  4,081  2,121   \n",
       "\n",
       "  Race_a Race_m Race_o Households  \n",
       "0  1,403    955    124     11,431  \n",
       "1      6      0      0        144  \n",
       "2    401    386    172      6,256  \n",
       "3      0      0     46        349  \n",
       "4  1,624    820    106      8,290  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.DataFrame({\"zip\":zip_ , \"Population\":Population,\"income\":income,\"edu_high\":edu_high,\"Emp\":Emp,\"Race_w\":Race_w,\"Race_h\":Race_h,\"Race_b\":Race_b,\"Race_a\":Race_a,\"Race_m\":Race_m,\"Race_o\":Race_o,\"Households\":Households})\n",
    "#df1.to_csv(\"df_zipcode.csv\")\n",
    "\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transform import transform_number as tn  ## this is the transform module that we built\n",
    "\n",
    "df_zip = pd.read_csv(\"df_zipcode.csv\")\n",
    "### Population\n",
    "df_zip['Population'] = tn.clean_comma(df_zip['Population']).astype(\"int\")\n",
    "\n",
    "## num_high_edu\n",
    "df_zip['edu_high'] = tn.clean_comma(df_zip['edu_high'])\n",
    "convert =[]\n",
    "for i in df_zip['edu_high']:\n",
    "    convert.append(tn.convert_k (i))\n",
    "    \n",
    "df_zip['edu_high'] =convert\n",
    "\n",
    "\n",
    "##Households\n",
    "df_zip['Households'] = tn.clean_comma(df_zip['Households']).astype(\"int\")\n",
    "\n",
    "## Race\n",
    "for ii in ['Race_w','Race_h','Race_b','Race_a','Race_m','Race_o']:\n",
    "    df_zip[ii] = tn.clean_comma(df_zip[ii])\n",
    "    convert =[]\n",
    "    for i in df_zip[ii]:\n",
    "        convert.append(tn.convert_k (i))\n",
    "    df_zip[ii] =convert    \n",
    "\n",
    "## Employment\n",
    "\n",
    "df_zip['Emp'] = tn.clean_comma(df_zip['Emp'])\n",
    "convert =[]\n",
    "for i in df_zip['Emp']:\n",
    "    convert.append(tn.convert_k (i))\n",
    "df_zip['Emp'] =convert \n",
    "\n",
    "## Income\n",
    "df_zip['income'] = tn.convert_dollar(df_zip['income'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_zip.to_csv(\"df_zipcode_clean.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
